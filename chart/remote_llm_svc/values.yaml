# Default values for remote_llm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

container:
  image: chengendu/remote-llm:latest
  resources:
    limits:
      cpu: 8
      memory: 32G
      nvidia_gpu: 1
    requests:
      cpu: 4
      memory: 4G
      nvidia_gpu: 1

service:
  type: NodePort
  port: 30300

configMap:
  inference_model_path: meta-llama/Llama-2-7b-chat-hf

secret:
  token: <-huggingface-access-token->
