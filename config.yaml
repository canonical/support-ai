# [llm]
#   type: llamacpp/openai/huggingface_pipeline
#   model
#   {openai}
#     api_key

basic_model:
  llm:
    type: huggingface_pipeline
    model: databricks/dolly-v2-12b
memory:
  db_connection: "mongodb://XXX"
datasources:
  - type: salesforce
    authentication:
      username: ""
      password: ""
      token: ""
    llm:
      # type can be one of llamacpp/openai/huggingface_pipeline
      type: huggingface_pipeline
      # model can be absolute path where model you directly downloaded.
      # for example. if you want to use dolphin-2.2.1-mistral-7b.Q5_K_M.gguf model, 
      # you can download it from huggingface and place the location of it.
      model: databricks/dolly-v2-12b
    embeddings:
      type: huggingface_pipeline
      model: databricks/dolly-v2-12b
  - type: knowledgebase
    authentication:
      username: ""
      password: ""
      token: ""
    llm:
      type: huggingface_pipeline
      model: databricks/dolly-v2-12b
    embeddings:
      type: huggingface_pipeline
      model: databricks/dolly-v2-12b
